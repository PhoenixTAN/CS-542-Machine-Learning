{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4878436297570695298\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4930941747\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16081296924131418185\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LIST = os.listdir('all/train')\n",
    "DATASET_PATH  = 'all/train'\n",
    "TEST_DIR =  'all/test'\n",
    "IMAGE_SIZE    = (224, 224)\n",
    "NUM_CLASSES   = len(DATA_LIST)\n",
    "BATCH_SIZE    = 10  # try reducing batch size or freeze more layers if your GPU runs out of memory\n",
    "NUM_EPOCHS    = 100\n",
    "LEARNING_RATE = 0.0001 # start off with high rate first 0.001 and experiment with reducing it gradually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 216 images belonging to 4 classes.\n",
      "Found 54 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanzi\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:341: UserWarning: This ImageDataGenerator specifies `zca_whitening` which overrides setting of`featurewise_std_normalization`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=50,featurewise_center = True,\n",
    "                                   featurewise_std_normalization = True,width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,shear_range=0.25,zoom_range=0.1,\n",
    "                                   zca_whitening = True,channel_shift_range = 20,\n",
    "                                   horizontal_flip = True,vertical_flip = True,\n",
    "                                   validation_split = 0.2,fill_mode='constant')\n",
    "\n",
    "\n",
    "train_batches = train_datagen.flow_from_directory(DATASET_PATH,target_size=IMAGE_SIZE,\n",
    "                                                  shuffle=True,batch_size=BATCH_SIZE,\n",
    "                                                  subset = \"training\",seed=42,\n",
    "                                                  class_mode=\"categorical\")\n",
    "\n",
    "valid_batches = train_datagen.flow_from_directory(DATASET_PATH,target_size=IMAGE_SIZE,\n",
    "                                                  shuffle=True,batch_size=BATCH_SIZE,\n",
    "                                                  subset = \"validation\",\n",
    "                                                  seed=42,class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 7, 7, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               25690368  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 46,552,876\n",
      "Trainable params: 25,691,396\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# raise NotImplementedError(\"Build your model based on an architecture of your choice \"\n",
    "#                           \"A sample model summary is shown below\")\n",
    "\n",
    "# Implement VGG16\n",
    "# from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "xception_model = tf.keras.applications.xception.Xception(include_top=False, weights='imagenet', input_shape=(224, 224, 3), pooling='None', classes=4)\n",
    "            \n",
    "xception_model.trainable = False\n",
    "\n",
    "covid_model = Sequential()\n",
    "covid_model.add(xception_model)\n",
    "covid_model.add(Flatten())\n",
    "covid_model.add(Dense(256, activation='relu'))\n",
    "covid_model.add(Dropout(0.2))\n",
    "covid_model.add(Dense(4, activation=None))\n",
    "\n",
    "covid_model.build(input_shape=(224, 224, 3))\n",
    "covid_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "6\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3279032868296368878\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4930941747\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17711188938040944759\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanzi\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\tanzi\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:735: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 22 steps, validate for 6 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanzi\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\tanzi\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:735: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 10s 440ms/step - loss: 14.0132 - accuracy: 0.3056 - val_loss: 9.4871 - val_accuracy: 0.4259\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 6s 278ms/step - loss: 4.8208 - accuracy: 0.3935 - val_loss: 4.1242 - val_accuracy: 0.4444\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 6s 279ms/step - loss: 2.1398 - accuracy: 0.5463 - val_loss: 2.7902 - val_accuracy: 0.4074\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 6s 281ms/step - loss: 1.1111 - accuracy: 0.5648 - val_loss: 1.7395 - val_accuracy: 0.4259\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 6s 282ms/step - loss: 1.1995 - accuracy: 0.4769 - val_loss: 1.7407 - val_accuracy: 0.2407\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 6s 279ms/step - loss: 1.1075 - accuracy: 0.5417 - val_loss: 1.7265 - val_accuracy: 0.3704\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 6s 283ms/step - loss: 1.1025 - accuracy: 0.5370 - val_loss: 2.5083 - val_accuracy: 0.3148\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 6s 292ms/step - loss: 0.9842 - accuracy: 0.5556 - val_loss: 1.9082 - val_accuracy: 0.2778\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 6s 292ms/step - loss: 1.0858 - accuracy: 0.5556 - val_loss: 2.0096 - val_accuracy: 0.3519\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 6s 284ms/step - loss: 0.8848 - accuracy: 0.6157 - val_loss: 0.9908 - val_accuracy: 0.5741\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 6s 281ms/step - loss: 0.9585 - accuracy: 0.5880 - val_loss: 1.5642 - val_accuracy: 0.3519\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 6s 283ms/step - loss: 0.8978 - accuracy: 0.6157 - val_loss: 1.4232 - val_accuracy: 0.4630\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 6s 294ms/step - loss: 0.8641 - accuracy: 0.6481 - val_loss: 1.5473 - val_accuracy: 0.4259\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 6s 288ms/step - loss: 1.0031 - accuracy: 0.5787 - val_loss: 1.6888 - val_accuracy: 0.3333\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 6s 284ms/step - loss: 0.9051 - accuracy: 0.5602 - val_loss: 1.7398 - val_accuracy: 0.3704\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 6s 292ms/step - loss: 0.9515 - accuracy: 0.5787 - val_loss: 2.0912 - val_accuracy: 0.3148\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 6s 282ms/step - loss: 0.8966 - accuracy: 0.6111 - val_loss: 2.3388 - val_accuracy: 0.2963\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 7s 297ms/step - loss: 0.8952 - accuracy: 0.5972 - val_loss: 1.6898 - val_accuracy: 0.3704\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 6s 279ms/step - loss: 0.8035 - accuracy: 0.6296 - val_loss: 2.2792 - val_accuracy: 0.3333\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 6s 279ms/step - loss: 0.8996 - accuracy: 0.6435 - val_loss: 1.5682 - val_accuracy: 0.3889\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 6s 280ms/step - loss: 0.8540 - accuracy: 0.6343 - val_loss: 1.5293 - val_accuracy: 0.3704\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 6s 283ms/step - loss: 0.9669 - accuracy: 0.5787 - val_loss: 1.0684 - val_accuracy: 0.4630\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 6s 282ms/step - loss: 0.8208 - accuracy: 0.6343 - val_loss: 1.4139 - val_accuracy: 0.4815\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 6s 286ms/step - loss: 0.8254 - accuracy: 0.6296 - val_loss: 1.3385 - val_accuracy: 0.4259\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 6s 289ms/step - loss: 0.7894 - accuracy: 0.6435 - val_loss: 2.6231 - val_accuracy: 0.3333\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 6s 289ms/step - loss: 0.9061 - accuracy: 0.6667 - val_loss: 1.5101 - val_accuracy: 0.4815\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 6s 281ms/step - loss: 0.8345 - accuracy: 0.6620 - val_loss: 1.2861 - val_accuracy: 0.4074\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 6s 285ms/step - loss: 0.8299 - accuracy: 0.6065 - val_loss: 1.3625 - val_accuracy: 0.4259\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 6s 288ms/step - loss: 0.9005 - accuracy: 0.6111 - val_loss: 1.3706 - val_accuracy: 0.4630\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 6s 284ms/step - loss: 0.7004 - accuracy: 0.7176 - val_loss: 1.8478 - val_accuracy: 0.4444\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 6s 285ms/step - loss: 0.7871 - accuracy: 0.6574 - val_loss: 1.5719 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 6s 284ms/step - loss: 0.8466 - accuracy: 0.6528 - val_loss: 2.2779 - val_accuracy: 0.3889\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 6s 281ms/step - loss: 0.8813 - accuracy: 0.6343 - val_loss: 1.7600 - val_accuracy: 0.3889\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 6s 279ms/step - loss: 0.7415 - accuracy: 0.6481 - val_loss: 1.5796 - val_accuracy: 0.4630\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 6s 279ms/step - loss: 0.7974 - accuracy: 0.6435 - val_loss: 1.3929 - val_accuracy: 0.4630\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 6s 279ms/step - loss: 0.6522 - accuracy: 0.7083 - val_loss: 1.7273 - val_accuracy: 0.4444\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 6s 281ms/step - loss: 0.7765 - accuracy: 0.6389 - val_loss: 1.2902 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 6s 279ms/step - loss: 0.7484 - accuracy: 0.6898 - val_loss: 1.4814 - val_accuracy: 0.4815\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 6s 280ms/step - loss: 0.7634 - accuracy: 0.6852 - val_loss: 1.4483 - val_accuracy: 0.4074\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 6s 290ms/step - loss: 0.8629 - accuracy: 0.6806 - val_loss: 1.6003 - val_accuracy: 0.4259\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 6s 285ms/step - loss: 0.7219 - accuracy: 0.6898 - val_loss: 1.5643 - val_accuracy: 0.3333\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 6s 283ms/step - loss: 0.7278 - accuracy: 0.6806 - val_loss: 2.0341 - val_accuracy: 0.3519\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 6s 285ms/step - loss: 0.7618 - accuracy: 0.6806 - val_loss: 1.5748 - val_accuracy: 0.3519\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 6s 284ms/step - loss: 0.7078 - accuracy: 0.7222 - val_loss: 1.5557 - val_accuracy: 0.4074\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 6s 284ms/step - loss: 0.7960 - accuracy: 0.6667 - val_loss: 1.7331 - val_accuracy: 0.3889\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 6s 285ms/step - loss: 0.6786 - accuracy: 0.7037 - val_loss: 2.1039 - val_accuracy: 0.3148\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 6s 293ms/step - loss: 0.6933 - accuracy: 0.7037 - val_loss: 1.8091 - val_accuracy: 0.3889\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 7s 301ms/step - loss: 0.7222 - accuracy: 0.7222 - val_loss: 1.8710 - val_accuracy: 0.4074\n",
      "Epoch 49/100\n",
      "13/22 [================>.............] - ETA: 2s - loss: 0.6585 - accuracy: 0.7143"
     ]
    }
   ],
   "source": [
    "# FIT MODEL\n",
    "print(len(train_batches))\n",
    "print(len(valid_batches))\n",
    "\n",
    "STEP_SIZE_TRAIN=train_batches.n//train_batches.batch_size\n",
    "STEP_SIZE_VALID=valid_batches.n//valid_batches.batch_size\n",
    "\n",
    "# raise NotImplementedError(\"Use the model.fit function to train your network\")\n",
    "covid_model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "# print the device library\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "history = None\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    history = covid_model.fit(train_batches, epochs=100, validation_data=(valid_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# raise NotImplementedError(\"Plot the accuracy and the loss during training\")\n",
    "\n",
    "# Accuracy over 40 Epochs\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='train accuracy') \n",
    "plt.plot(history.history['val_accuracy'], label = 'validation accuracy') \n",
    "plt.title('Accuracy over 40 epochs')\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Accuracy') \n",
    "plt.ylim([0.4, 1.1]) \n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Loss over 40 Epochs\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='train loss') \n",
    "plt.plot(history.history['val_loss'], label = 'validation loss') \n",
    "plt.title('Loss over 40 epochs')\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Loss') \n",
    "plt.ylim([0, 1.2]) \n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "eval_generator = test_datagen.flow_from_directory(TEST_DIR,target_size=IMAGE_SIZE,\n",
    "                                                  batch_size=1,shuffle=True,seed=42,class_mode=\"categorical\")\n",
    "eval_generator.reset()\n",
    "print(len(eval_generator))\n",
    "x = covid_model.evaluate_generator(eval_generator,steps = np.ceil(len(eval_generator)),\n",
    "                           use_multiprocessing = False,verbose = 1,workers=1)\n",
    "print('Test loss:' , x[0])\n",
    "print('Test accuracy:',x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "intermediate_layer_model = tf.keras.models.Model(inputs=covid_model.input,\n",
    "                                        outputs=covid_model.get_layer('dense').output)\n",
    "\n",
    "tsne_eval_generator = test_datagen.flow_from_directory(DATASET_PATH,target_size=IMAGE_SIZE,\n",
    "                                                  batch_size=1,shuffle=False,seed=42,class_mode=\"categorical\")\n",
    "\n",
    "# raise NotImplementedError(\"Extract features from the tsne_data_generator and fit a t-SNE model for the features,\"\n",
    "#                           \"and plot the resulting 2D features of the four classes.\")\n",
    "\n",
    "outputs = intermediate_layer_model.predict_generator(tsne_eval_generator,270,verbose=1)\n",
    "print(outputs.shape)\n",
    "label = tsne_eval_generator.classes\n",
    "features = TSNE(n_components=2).fit_transform(outputs)\n",
    "print(features.shape)\n",
    "# 到底是获取参数还是输出\n",
    "plt.figure()\n",
    "for index in range(len(features)):\n",
    "    if label[index] == 0:\n",
    "        # COVID\n",
    "        plt.plot(features[index, 0], features[index, 1], 'bo')\n",
    "    elif label[index] == 1:\n",
    "        # normal\n",
    "        plt.plot(features[index, 0], features[index, 1], 'yo')\n",
    "    elif label[index] == 2:\n",
    "        # Pneumonia_bac\n",
    "        plt.plot(features[index, 0], features[index, 1], 'go')\n",
    "    else:\n",
    "        # Pneumonia_vir\n",
    "        plt.plot(features[index, 0], features[index, 1], 'ro')\n",
    "plt.title('2D features')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
