{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1d234e3f-af8b-4757-83f3-241b04b7a511"
    }
   },
   "source": [
    "# Class Challenge: Image Classification of COVID-19 X-rays\n",
    "# Task 1 [Total points: 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b07b9992-b592-4871-9f9a-3b0ae5fa8b5f"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "* This assignment involves the following packages: 'matplotlib', 'numpy', and 'sklearn'. \n",
    "\n",
    "* If you are using conda, use the following commands to install the above packages:<br>\n",
    "```shell\n",
    "conda install matplotlib\n",
    "conda install numpy\n",
    "conda install -c anaconda scikit-learn\n",
    "```\n",
    "\n",
    "* If you are using pip, use use the following commands to install the above packages: <br> \n",
    "```shell\n",
    "pip install matplotlib\n",
    "pip install numpy\n",
    "pip install sklearn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5516f610-f00c-43c3-bf19-4cf7ab9c089f"
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "Please download the data using the following link: [COVID-19](https://drive.google.com/file/d/1Y88tgqpQ1Pjko_7rntcPowOJs_QNOrJ-/view). \n",
    "\n",
    "* After downloading 'Covid_Data_GradientCrescent.zip', unzip the file and you should see the following data structure:\n",
    "\n",
    "\n",
    "|--all<br>\n",
    "|--------train<br>\n",
    "|--------test<br>\n",
    "|--two<br>\n",
    "|--------train<br>\n",
    "|--------test<br>\n",
    "\n",
    "\n",
    "* Put the 'all' folder, the 'two' folder and this python notebook in the **same directory** so that the following code can correctly locate the data.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "## [20 points] Binary Classification: COVID-19 vs. Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "5e05f980-3d14-4367-b3d1-664249145b13"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "58317664-8da3-4283-b3e5-35721687e7ab"
    }
   },
   "outputs": [],
   "source": [
    "DATA_LIST = os.listdir('two/train')\n",
    "DATASET_PATH  = 'two/train'\n",
    "TEST_DIR =  'two/test'\n",
    "IMAGE_SIZE    = (224, 224)\n",
    "NUM_CLASSES   = len(DATA_LIST)\n",
    "BATCH_SIZE    = 10  # try reducing batch size or freeze more layers if your GPU runs out of memory\n",
    "NUM_EPOCHS    = 40\n",
    "LEARNING_RATE = 0.0005 # start off with high rate first 0.001 and experiment with reducing it gradually "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### Generate Training and Validation Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "71760e29-2b08-4259-93f1-ebe68cd74a6d"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanzi\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:341: UserWarning: This ImageDataGenerator specifies `zca_whitening` which overrides setting of`featurewise_std_normalization`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 104 images belonging to 2 classes.\n",
      "Found 26 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=50,featurewise_center = True,\n",
    "                                   featurewise_std_normalization = True,width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,shear_range=0.25,zoom_range=0.1,\n",
    "                                   zca_whitening = True,channel_shift_range = 20,\n",
    "                                   horizontal_flip = True,vertical_flip = True,\n",
    "                                   validation_split = 0.2,fill_mode='constant')\n",
    "\n",
    "train_batches = train_datagen.flow_from_directory(DATASET_PATH,target_size=IMAGE_SIZE,\n",
    "                                                  shuffle=True,batch_size=BATCH_SIZE,\n",
    "                                                  subset = \"training\",seed=42,\n",
    "                                                  class_mode=\"binary\")\n",
    "\n",
    "valid_batches = train_datagen.flow_from_directory(DATASET_PATH,target_size=IMAGE_SIZE,\n",
    "                                                  shuffle=True,batch_size=BATCH_SIZE,\n",
    "                                                  subset = \"validation\",seed=42,\n",
    "                                                  class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### [10 points] Build Model\n",
    "Hint: Starting from **a pre-trained model** typically helps performance on a new task, e.g. starting with weights obtained by training on ImageNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "5c52eeb2-1092-4d45-9e16-02219c82cb5e"
    }
   },
   "outputs": [],
   "source": [
    "# raise NotImplementedError(\"Build your model based on an architecture of your choice \"\n",
    "#                           \"A sample model summary is shown below\")\n",
    "\n",
    "# Implement VGG16\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg_16 = VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "\n",
    "# Arguments\n",
    "\n",
    "# vgg_16.trainable = False\n",
    "\n",
    "# covid_model = models.Sequential()\n",
    "# covid_model.add(vgg_16)\n",
    "# covid_model.add(layers.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### [5 points] Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "cdb90d24-6a23-4969-8138-f37e7050062d"
    }
   },
   "outputs": [],
   "source": [
    "#FIT MODEL\n",
    "print(len(train_batches))\n",
    "print(len(valid_batches))\n",
    "\n",
    "STEP_SIZE_TRAIN=train_batches.n//train_batches.batch_size\n",
    "STEP_SIZE_VALID=valid_batches.n//valid_batches.batch_size\n",
    "\n",
    "raise NotImplementedError(\"Use the model.fit function to train your network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### [5 points] Plot Accuracy and Loss During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "ff342098-784a-4e20-ac34-b74ca8ebe839"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "raise NotImplementedError(\"Plot the accuracy and the loss during training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### Plot Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "eval_generator = test_datagen.flow_from_directory(TEST_DIR,target_size=IMAGE_SIZE,\n",
    "                                                  batch_size=1,shuffle=True,seed=42,class_mode=\"binary\")\n",
    "eval_generator.reset()\n",
    "pred = model.predict_generator(eval_generator,18,verbose=1)\n",
    "for index, probability in enumerate(pred):\n",
    "    image_path = TEST_DIR + \"/\" +eval_generator.filenames[index]\n",
    "    image = mpimg.imread(image_path)\n",
    "    if image.ndim < 3:\n",
    "        image = np.reshape(image,(image.shape[0],image.shape[1],1))\n",
    "        image = np.concatenate([image, image, image], 2)\n",
    "#         print(image.shape)\n",
    "\n",
    "    pixels = np.array(image)\n",
    "    plt.imshow(pixels)\n",
    "    \n",
    "    print(eval_generator.filenames[index])\n",
    "    if probability > 0.5:\n",
    "        plt.title(\"%.2f\" % (probability[0]*100) + \"% Normal\")\n",
    "    else:\n",
    "        plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% COVID19 Pneumonia\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "## [10 points] TSNE Plot\n",
    "t-Distributed Stochastic Neighbor Embedding (t-SNE) is a widely used technique for dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets. After training is complete, extract features from a specific deep layer of your choice, use t-SNE to reduce the dimensionality of your extracted features to 2 dimensions and plot the resulting 2D features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "intermediate_layer_model = models.Model(inputs=model.input,\n",
    "                                        outputs=model.get_layer('dense_feature').output)\n",
    "tsne_data_generator = test_datagen.flow_from_directory(DATASET_PATH,target_size=IMAGE_SIZE,\n",
    "                                                  batch_size=1,shuffle=True,seed=42,class_mode=\"binary\")\n",
    "\n",
    "raise NotImplementedError(\"Extract features from the tsne_data_generator and fit a t-SNE model for the features,\"\n",
    "                          \"and plot the resulting 2D features of the two classes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Task 2: COVID-19 vs Normal vs Tertiary Pneumonia (Bacterial and Viral) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "<!-- #### Renew Training Batch and Validation Batch -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "<!-- #### Renew Model -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
