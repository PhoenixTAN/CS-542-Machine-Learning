{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1d234e3f-af8b-4757-83f3-241b04b7a511"
    }
   },
   "source": [
    "# Class Challenge: Image Classification of COVID-19 X-rays\n",
    "# Task 2 [Total points: 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b07b9992-b592-4871-9f9a-3b0ae5fa8b5f"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "* This assignment involves the following packages: 'matplotlib', 'numpy', and 'sklearn'. \n",
    "\n",
    "* If you are using conda, use the following commands to install the above packages:<br>\n",
    "```shell\n",
    "conda install matplotlib\n",
    "conda install numpy\n",
    "conda install -c anaconda scikit-learn\n",
    "```\n",
    "\n",
    "* If you are using pip, use use the following commands to install the above packages: <br> \n",
    "```shell\n",
    "pip install matplotlib\n",
    "pip install numpy\n",
    "pip install sklearn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5516f610-f00c-43c3-bf19-4cf7ab9c089f"
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "Please download the data using the following link: [COVID-19](https://drive.google.com/file/d/1Y88tgqpQ1Pjko_7rntcPowOJs_QNOrJ-/view). \n",
    "\n",
    "* After downloading 'Covid_Data_GradientCrescent.zip', unzip the file and you should see the following data structure:\n",
    "\n",
    "\n",
    "|--all<br>\n",
    "|--------train<br>\n",
    "|--------test<br>\n",
    "|--two<br>\n",
    "|--------train<br>\n",
    "|--------test<br>\n",
    "\n",
    "\n",
    "* Put the 'all' folder, the 'two' folder and this python notebook in the **same directory** so that the following code can correctly locate the data.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "## [20 points] Multi-class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "5e05f980-3d14-4367-b3d1-664249145b13"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "58317664-8da3-4283-b3e5-35721687e7ab"
    }
   },
   "outputs": [],
   "source": [
    "DATA_LIST = os.listdir('all/train')\n",
    "DATASET_PATH  = 'all/train'\n",
    "TEST_DIR =  'all/test'\n",
    "IMAGE_SIZE    = (224, 224)\n",
    "NUM_CLASSES   = len(DATA_LIST)\n",
    "BATCH_SIZE    = 10  # try reducing batch size or freeze more layers if your GPU runs out of memory\n",
    "NUM_EPOCHS    = 100\n",
    "LEARNING_RATE = 0.0001 # start off with high rate first 0.001 and experiment with reducing it gradually "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### Generate Training and Validation Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "71760e29-2b08-4259-93f1-ebe68cd74a6d"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanzi\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:341: UserWarning: This ImageDataGenerator specifies `zca_whitening` which overrides setting of`featurewise_std_normalization`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 216 images belonging to 4 classes.\n",
      "Found 54 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=50,featurewise_center = True,\n",
    "                                   featurewise_std_normalization = True,width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,shear_range=0.25,zoom_range=0.1,\n",
    "                                   zca_whitening = True,channel_shift_range = 20,\n",
    "                                   horizontal_flip = True,vertical_flip = True,\n",
    "                                   validation_split = 0.2,fill_mode='constant')\n",
    "\n",
    "\n",
    "train_batches = train_datagen.flow_from_directory(DATASET_PATH,target_size=IMAGE_SIZE,\n",
    "                                                  shuffle=True,batch_size=BATCH_SIZE,\n",
    "                                                  subset = \"training\",seed=42,\n",
    "                                                  class_mode=\"categorical\")\n",
    "\n",
    "valid_batches = train_datagen.flow_from_directory(DATASET_PATH,target_size=IMAGE_SIZE,\n",
    "                                                  shuffle=True,batch_size=BATCH_SIZE,\n",
    "                                                  subset = \"validation\",\n",
    "                                                  seed=42,class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### [10 points] Build Model\n",
    "Hint: Starting from a pre-trained model typically helps performance on a new task, e.g. starting with weights obtained by training on ImageNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "5c52eeb2-1092-4d45-9e16-02219c82cb5e"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 21,138,500\n",
      "Trainable params: 6,423,812\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# raise NotImplementedError(\"Build your model based on an architecture of your choice \"\n",
    "#                           \"A sample model summary is shown below\")\n",
    "\n",
    "# Implement VGG16\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# vgg_16 = VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "vgg_16 = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3), pooling='None', classes=4)\n",
    "            \n",
    "vgg_16.trainable = False\n",
    "\n",
    "covid_model = Sequential()\n",
    "covid_model.add(vgg_16)\n",
    "covid_model.add(Flatten())\n",
    "covid_model.add(Dense(256, activation='relu'))\n",
    "# covid_model.add(Dropout(0.2))\n",
    "covid_model.add(Dense(4, activation=None))\n",
    "\n",
    "covid_model.build(input_shape=(224, 224, 3))\n",
    "covid_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### [5 points] Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "cdb90d24-6a23-4969-8138-f37e7050062d"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanzi\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\tanzi\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:735: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 22 steps, validate for 6 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanzi\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\tanzi\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:735: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 27s 1s/step - loss: 2.3984 - accuracy: 0.3611 - val_loss: 1.4438 - val_accuracy: 0.4074\n",
      "Epoch 2/100\n",
      "20/22 [==========================>...] - ETA: 2s - loss: 1.3095 - accuracy: 0.4235"
     ]
    }
   ],
   "source": [
    "#FIT MODEL\n",
    "print(len(train_batches))\n",
    "print(len(valid_batches))\n",
    "\n",
    "STEP_SIZE_TRAIN=train_batches.n//train_batches.batch_size\n",
    "STEP_SIZE_VALID=valid_batches.n//valid_batches.batch_size\n",
    "\n",
    "# raise NotImplementedError(\"Use the model.fit function to train your network\")\n",
    "covid_model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "history = covid_model.fit(train_batches, epochs=100, validation_data=(valid_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### [5 points] Plot Accuracy and Loss During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "ff342098-784a-4e20-ac34-b74ca8ebe839"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# raise NotImplementedError(\"Plot the accuracy and the loss during training\")\n",
    "\n",
    "# Accuracy over 40 Epochs\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='train accuracy') \n",
    "plt.plot(history.history['val_accuracy'], label = 'validation accuracy') \n",
    "plt.title('Accuracy over 40 epochs')\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Accuracy') \n",
    "plt.ylim([0.4, 1.1]) \n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Loss over 40 Epochs\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='train loss') \n",
    "plt.plot(history.history['val_loss'], label = 'validation loss') \n",
    "plt.title('Loss over 40 epochs')\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Loss') \n",
    "plt.ylim([0, 1.2]) \n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "#### Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "eval_generator = test_datagen.flow_from_directory(TEST_DIR,target_size=IMAGE_SIZE,\n",
    "                                                  batch_size=1,shuffle=True,seed=42,class_mode=\"categorical\")\n",
    "eval_generator.reset()\n",
    "print(len(eval_generator))\n",
    "x = model.evaluate_generator(eval_generator,steps = np.ceil(len(eval_generator)),\n",
    "                           use_multiprocessing = False,verbose = 1,workers=1)\n",
    "print('Test loss:' , x[0])\n",
    "print('Test accuracy:',x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "source": [
    "## [10 points] TSNE Plot\n",
    "t-Distributed Stochastic Neighbor Embedding (t-SNE) is a widely used technique for dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets. After training is complete, extract features from a specific deep layer of your choice, use t-SNE to reduce the dimensionality of your extracted features to 2 dimensions and plot the resulting 2D features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "intermediate_layer_model = models.Model(inputs=model.input,\n",
    "                                        outputs=model.get_layer('feature_dense').output)\n",
    "\n",
    "tsne_eval_generator = test_datagen.flow_from_directory(DATASET_PATH,target_size=IMAGE_SIZE,\n",
    "                                                  batch_size=1,shuffle=False,seed=42,class_mode=\"categorical\")\n",
    "\n",
    "# raise NotImplementedError(\"Extract features from the tsne_data_generator and fit a t-SNE model for the features,\"\n",
    "#                           \"and plot the resulting 2D features of the four classes.\")\n",
    "\n",
    "outputs = intermediate_layer_model.predict_generator(tsne_data_generator,130,verbose=1)\n",
    "print(outputs.shape)\n",
    "label = tsne_data_generator.classes\n",
    "features = TSNE(n_components=2).fit_transform(outputs)\n",
    "print(features.shape)\n",
    "# 到底是获取参数还是输出\n",
    "plt.figure()\n",
    "for index in range(len(features)):\n",
    "    if label[index] == 0:\n",
    "        # COVID\n",
    "        plt.plot(features[index, 0], features[index, 1], 'bo')\n",
    "    elif label[index] == 1:\n",
    "        # normal\n",
    "        plt.plot(features[index, 0], features[index, 1], 'yo')\n",
    "    elif label[index] == 2:\n",
    "        # Pneumonia_bac\n",
    "        plt.plot(features[index, 0], features[index, 1], 'go')\n",
    "    else:\n",
    "        # Pneumonia_vir\n",
    "        plt.plot(features[index, 0], features[index, 1], 'ro')\n",
    "plt.title('2D features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "66140980-2aa4-457f-b1df-74c10c234cc2"
    }
   },
   "outputs": [],
   "source": [
    "# (1) Importing dependency\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten,Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "# (2) Get Data\n",
    "# import tflearn.datasets.oxflower17 as oxflower17\n",
    "# x, y = oxflower17.load_data(one_hot=True)\n",
    "\n",
    "# (3) Create a sequential model\n",
    "alex_net_model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "alex_net_model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
    "alex_net_model.add(Activation('relu'))\n",
    "# Pooling \n",
    "alex_net_model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation before passing it to the next layer\n",
    "alex_net_model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "alex_net_model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "alex_net_model.add(Activation('relu'))\n",
    "# Pooling\n",
    "alex_net_model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "alex_net_model.add(BatchNormalization())\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "alex_net_model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "alex_net_model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "alex_net_model.add(BatchNormalization())\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "alex_net_model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "alex_net_model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "alex_net_model.add(BatchNormalization())\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "alex_net_model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "alex_net_model.add(Activation('relu'))\n",
    "# Pooling\n",
    "alex_net_model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "alex_net_model.add(BatchNormalization())\n",
    "\n",
    "# Passing it to a dense layer\n",
    "alex_net_model.add(Flatten())\n",
    "# 1st Dense Layer\n",
    "alex_net_model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "alex_net_model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "alex_net_model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "alex_net_model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Dense Layer\n",
    "alex_net_model.add(Dense(4096))\n",
    "alex_net_model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "alex_net_model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "alex_net_model.add(BatchNormalization())\n",
    "\n",
    "# 3rd Dense Layer\n",
    "alex_net_model.add(Dense(1000))\n",
    "alex_net_model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "alex_net_model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "alex_net_model.add(BatchNormalization())\n",
    "\n",
    "# Output Layer\n",
    "alex_net_model.add(Dense(17))\n",
    "alex_net_model.add(Activation('softmax'))\n",
    "\n",
    "alex_net_model.summary()\n",
    "\n",
    "# (4) Compile \n",
    "alex_net_model.build(input_shape=(224, 224, 3))\n",
    "alex_net_model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# (5) Train\n",
    "alex_net_history = alex_net_model.fit(x, y, batch_size=64, epochs=1, verbose=1, validation_split=0.2, shuffle=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
