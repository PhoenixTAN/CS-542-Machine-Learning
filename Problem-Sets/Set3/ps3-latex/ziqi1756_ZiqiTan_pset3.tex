\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    
    \usepackage{iftex}
    \ifPDFTeX
    	\usepackage[T1]{fontenc}
    	\usepackage{mathpazo}
    \else
    	\usepackage{fontspec}
    \fi

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}
    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range
    \makeatletter % fix for grffile with XeLaTeX
    \def\Gread@@xetex#1{%
      \IfFileExists{"\Gin@base".bb}%
      {\Gread@eps{\Gin@base.bb}}%
      {\Gread@@xetex@aux#1}%
    }
    \makeatother

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{ziqi1756\_ZiqiTan\_pset3}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        \ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{problem-set-3-neural-networks}{%
\section{Problem Set 3: Neural
Networks}\label{problem-set-3-neural-networks}}

This assignment requires a working IPython Notebook installation, which
you should already have. If not, please refer to the instructions in the
course resources.

The programming part is adapted from
\href{http://cs231n.stanford.edu/}{Stanford CS231n}.

\hypertarget{in-part-2-programming-of-this-assignment-you-do-not-need-to-make-any-modification-code-in-this-ipython-notebook.-instead-you-will-implement-your-own-simple-neural-network-in-the-mlp.py-file.-please-attach-your-written-solutions-for-part-1-and-part-3-in-this-ipython-notebook.}{%
\subsubsection{In part 2 (programming) of this assignment, you DO NOT
need to make any modification code in this IPython Notebook. Instead you
will implement your own simple neural network in the mlp.py file. Please
attach your written solutions for part 1 and part 3 in this IPython
Notebook.}\label{in-part-2-programming-of-this-assignment-you-do-not-need-to-make-any-modification-code-in-this-ipython-notebook.-instead-you-will-implement-your-own-simple-neural-network-in-the-mlp.py-file.-please-attach-your-written-solutions-for-part-1-and-part-3-in-this-ipython-notebook.}}

Total: 80 points.

    \hypertarget{pts-problem-1-backprop-in-a-simple-mlp}{%
\subsection{{[}30pts{]} Problem 1: Backprop in a simple
MLP}\label{pts-problem-1-backprop-in-a-simple-mlp}}

This problem asks you to derive all the steps of the backpropagation
algorithm for a simple classification network. Consider a
fully-connected neural network, also known as a multi-layer perceptron
(MLP), with a single hidden layer and a one-node output layer. The
hidden and output nodes use an elementwise sigmoid activation function
and the loss layer uses cross-entropy loss:

\[ f(z)=\frac{1}{1+exp(-z))} \]

\[ L(\hat{y},y)=-yln(\hat{y}) - (1-y)ln(1-\hat{y}) \]

The computation graph for an example network is shown below. Note that
it has an equal number of nodes in the input and hidden layer (3 each),
but, in general, they need not be equal. Also, to make the application
of backprop easier, we show the computation graph which shows the dot
product and activation functions as their own nodes, rather than the
usual graph showing a single node for both.

The forward and backward computation are given below. NOTE: We assume no
regularization, so you can omit the terms involving \(\Omega\).

The forward step is:

and the backward step is:

    Write down each step of the backward pass explicitly for all layers,
i.e.~for the loss and \(k=2,1\), compute all gradients above, expressing
them as a function of variables \(x, y, h, W, b\). We start by giving an
example. Note that \(\odot\) stands for element-wise multiplication.

\[ \nabla_{\hat{y}}L(\hat{y},y) =  \nabla_{\hat{y}}[-yln(\hat{y}) - (1-y)ln(1-\hat{y})] = \frac{\hat{y}-y}{(1-\hat{y})\hat{y}} = \frac{h^{(2)}-y}{(1-h^{(2)})h^{(2)}}\]

Next, please derive the following.

Hint: you should substitute the updated values for the gradient \(g\) in
each step and simplify as much as possible.

\textbf{Useful information about vectorized chain rule and
backpropagation}: If you are struggling with computing the vectorized
version of chain rule for the backpropagation question in problem set 4,
you may find this example helpful:
https://web.stanford.edu/class/cs224n/readings/gradient-notes.pdf It
also contains some helpful shortcuts for computing gradients.

    \textbf{{[}5pts{]} Q1.1}: \(\nabla_{a^{(2)}}J\)

    \[ \nabla_{a^{(2)}}L(\hat y, y) 
= \nabla_{\hat{y}}L(\hat{y},y) \nabla_{a^{(2)}} \hat y 
= \nabla_{\hat{y}}L(\hat{y},y) \nabla_{a^{(2)}} h^{(2)}
\]

\[ h^{(2)} = \frac{1}{1+exp(-a^{(2)})} \]

\[ \nabla_{a^{(2)}}L(\hat y, y) = \frac{h^{(2)}-y}{(1-h^{(2)})h^{(2)}}  (1-h^{(2)})h^{(2)} = h^{(2)} - y \]

    \textbf{{[}5pts{]} Q1.2}: \(\nabla_{b^{(2)}}J\)

    \[  \nabla_{b^{(2)}}L(\hat y, y) = \nabla_{a^{(2)}}L(\hat y, y) \nabla_{b^{(2)}}a^{(2)}\]

\[ a^{(2)} = h^{(1)} W^{(2)} + b^{(2)}\]

\[ \nabla_{b^{(2)}}L(\hat y, y) =  h^{(2)} - y\]

    \textbf{{[}5pts{]} Q1.3}: \(\nabla_{W^{(2)}}J\) Hint: this should be a
vector, since \(W^{(2)}\) is a vector. 

    \[ \nabla_{W^{(2)}}L(\hat y, y) =  \nabla_{a^{(2)}}L(\hat y, y) \nabla_{W^{(2)}}a^{(2)} \]

\[
\nabla_{W^{(2)}}L(\hat y, y) =
(h^{(2)} - y)
 \begin{bmatrix}
h^{(1)}_{1} \\
h^{(1)}_{2} \\
h^{(1)}_{3}
\end{bmatrix} 
\]

    \textbf{{[}5pts{]} Q1.4}: \(\nabla_{h^{(1)}}J\)

    \[ \nabla_{h^{(1)}}L(\hat y, y) = \nabla_{a^{(2)}}L(\hat y, y) \nabla_{h^{(1)}}a^{(2)}\]

\[
\nabla_{h^{(1)}}L(\hat y, y) =
(h^{(2)} - y) 
 \begin{bmatrix}
W^{(2)}_{1} \\
W^{(2)}_{2} \\
W^{(2)}_{3}
\end{bmatrix} 
\]

    \textbf{{[}5pts{]} Q1.5}: \(\nabla_{b^{(1)}}J\), \(\nabla_{W^{(1)}}J\)

    \[ a^{(1)} = h^{(0)}  W^{(1)} + b^{(1)}\]
\[ h^{(1)} = \frac{1}{1+exp(-a^{(1)})}\]

\[ \nabla_{a^{(1)}}L(\hat y, y) = \nabla_{h^{(1)}}L(\hat y, y) \nabla_{a^{(1)}}h^{(1)} \]

\[ 
\nabla_{a^{(1)}}L(\hat y, y) =
(h^{(2)} - y) h^{(1)} \odot (1-h^{(1)}) \odot
 \begin{bmatrix}
W^{(2)}_{1} \\
W^{(2)}_{2} \\
W^{(2)}_{3}
\end{bmatrix}  \]

\[
\nabla_{b^{(1)}}L(\hat y, y) = \nabla_{a^{(1)}}L(\hat y, y) \nabla_{b^{(1)}}a^{(1)}
=
(h^{(2)} - y) h^{(1)} \odot (1-h^{(1)}) \odot
 \begin{bmatrix}
W^{(2)}_{1} \\
W^{(2)}_{2} \\
W^{(2)}_{3}
\end{bmatrix}
\]

\[
\nabla_{W^{(1)}}L(\hat y, y) = \nabla_{a^{(1)}}L(\hat y, y) \nabla_{W^{(1)}}a^{(1)}
=
(h^{(2)} - y) h^{(1)} \odot (1-h^{(1)}) \odot
 \begin{bmatrix}
W^{(2)}_{1} \\
W^{(2)}_{2} \\
W^{(2)}_{3}
\end{bmatrix}
\odot
\begin{bmatrix}
h^{(0)}_{1} \\
h^{(0)}_{2} \\
h^{(0)}_{3}
\end{bmatrix}
\]

    \textbf{{[}5pts{]} Q1.6} Briefly, explain how the computational speed of
backpropagation would be affected if it did not include a forward pass

    If it did not include a forwad pass, the speed of backpropagation would
become slow. When backpropagating, we need some intermediate variables,
such as \(h^{(2)}\) and \(h^{(1)}\).

    \hypertarget{pts-problem-2-programming-implementing-a-simple-mlp}{%
\subsection{{[}30pts{]} Problem 2 (Programming): Implementing a simple
MLP}\label{pts-problem-2-programming-implementing-a-simple-mlp}}

In this problem we will develop a neural network with fully-connected
layers, or Multi-Layer Perceptron (MLP). We will use it in
classification tasks.

In the current directory, you can find a file \texttt{mlp.py}, which
contains the definition for class \texttt{TwoLayerMLP}. As the name
suggests, it implements a 2-layer MLP, or MLP with 1 \emph{hidden}
layer. You will implement your code in the same file, and call the
member functions in this notebook. Below is some initialization. The
\texttt{autoreload} command makes sure that \texttt{mlp.py} is
periodically reloaded.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} setup}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\PY{k+kn}{from} \PY{n+nn}{mlp} \PY{k}{import} \PY{n}{TwoLayerMLP}

\PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
\PY{n}{plt}\PY{o}{.}\PY{n}{rcParams}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{figure.figsize}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{p}{(}\PY{l+m+mf}{10.0}\PY{p}{,} \PY{l+m+mf}{8.0}\PY{p}{)} \PY{c+c1}{\PYZsh{} set default size of plots}
\PY{n}{plt}\PY{o}{.}\PY{n}{rcParams}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{image.interpolation}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{nearest}\PY{l+s+s1}{\PYZsq{}}
\PY{n}{plt}\PY{o}{.}\PY{n}{rcParams}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{image.cmap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gray}\PY{l+s+s1}{\PYZsq{}}

\PY{c+c1}{\PYZsh{} for auto\PYZhy{}reloading external modules}
\PY{c+c1}{\PYZsh{} see http://stackoverflow.com/questions/1907993/autoreload\PYZhy{}of\PYZhy{}modules\PYZhy{}in\PYZhy{}ipython}
\PY{o}{\PYZpc{}}\PY{k}{load\PYZus{}ext} autoreload
\PY{o}{\PYZpc{}}\PY{k}{autoreload} 2    \PYZsh{} command makes sure that mlp.py is periodically reloaded

\PY{k}{def} \PY{n+nf}{rel\PYZus{}error}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{} returns relative error \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{abs}\PY{p}{(}\PY{n}{x} \PY{o}{\PYZhy{}} \PY{n}{y}\PY{p}{)} \PY{o}{/} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{maximum}\PY{p}{(}\PY{l+m+mf}{1e\PYZhy{}8}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{abs}\PY{p}{(}\PY{n}{x}\PY{p}{)} \PY{o}{+} \PY{n}{np}\PY{o}{.}\PY{n}{abs}\PY{p}{(}\PY{n}{y}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    Next we initialize a toy model and some toy data, the task is to
classify five 4-d vectors.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Create a small net and some toy data to check your implementations.}
\PY{c+c1}{\PYZsh{} Note that we set the random seed for repeatable experiments.}
\PY{n}{input\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{4}
\PY{n}{hidden\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{10}
\PY{n}{num\PYZus{}classes} \PY{o}{=} \PY{l+m+mi}{3}
\PY{n}{num\PYZus{}inputs} \PY{o}{=} \PY{l+m+mi}{5}

\PY{k}{def} \PY{n+nf}{init\PYZus{}toy\PYZus{}model}\PY{p}{(}\PY{n}{actv}\PY{p}{,} \PY{n}{std}\PY{o}{=}\PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{)}\PY{p}{:}
    \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
    \PY{k}{return} \PY{n}{TwoLayerMLP}\PY{p}{(}\PY{n}{input\PYZus{}size}\PY{p}{,} \PY{n}{hidden\PYZus{}size}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{p}{,} \PY{n}{std}\PY{o}{=}\PY{n}{std}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{n}{actv}\PY{p}{)}

\PY{k}{def} \PY{n+nf}{init\PYZus{}toy\PYZus{}data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
    \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}
    \PY{n}{X} \PY{o}{=} \PY{l+m+mi}{10} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{randn}\PY{p}{(}\PY{n}{num\PYZus{}inputs}\PY{p}{,} \PY{n}{input\PYZus{}size}\PY{p}{)}
    \PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
    \PY{k}{return} \PY{n}{X}\PY{p}{,} \PY{n}{y}

\PY{n}{X}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n}{init\PYZus{}toy\PYZus{}data}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X = }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{X}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y = }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
X =  [[ 16.24345364  -6.11756414  -5.28171752 -10.72968622]
 [  8.65407629 -23.01538697  17.44811764  -7.61206901]
 [  3.19039096  -2.49370375  14.62107937 -20.60140709]
 [ -3.22417204  -3.84054355  11.33769442 -10.99891267]
 [ -1.72428208  -8.77858418   0.42213747   5.82815214]]

y =  [0 1 2 2 1]
    \end{Verbatim}

    \hypertarget{pts-q2.1-forward-pass-sigmoid}{%
\subsubsection{{[}5pts{]} Q2.1 Forward pass:
Sigmoid}\label{pts-q2.1-forward-pass-sigmoid}}

Our 2-layer MLP uses a softmax output layer (\textbf{note}: this means
that you don't need to apply a sigmoid on the output) and the multiclass
cross-entropy loss to perform classification.

\textbf{Softmax function}: For class j:
\[P(y=j|x) = \frac{\exp(z_j)}{\sum_{k=1}^{K} \exp(z_k)}\]
\textbf{Multiclass cross-entropy loss function}: y - binary indicator (0
or 1) if class label c is the correct classification\\
\[J \ = \ \frac{1}{m} \ \sum_{i=1}^{m} \sum_{c=1}^{C} \ [ \ -y_{(c)} log(P(y_{(c)}|x^{(i)})) \ ]\]

Please take a look at method \texttt{TwoLayerMLP.loss} in the file
\texttt{mlp.py}. This function takes in the data and weight parameters,
and computes the class scores (aka logits), the loss \(L\), and the
gradients on the parameters.

\begin{itemize}
\tightlist
\item
  Complete the implementation of forward pass (up to the computation of
  \texttt{scores}) for the sigmoid activation:
  \(\sigma(x)=\frac{1}{1+exp(-x)}\).
\end{itemize}

\textbf{Note 1}: Softmax cross entropy loss involves the
\href{https://en.wikipedia.org/wiki/LogSumExp}{log-sum-exp operation}.
This can result in numerical underflow/overflow. Read about the solution
in the link, and try to understand the calculation of \texttt{loss} in
the code.

\textbf{Note 2}: You're strongly encouraged to implement in a vectorized
way and avoid using slower \texttt{for} loops. Note that most numpy
functions support vector inputs.

Check the correctness of your forward pass below. The difference should
be very small (\textless{}1e-6).

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{net} \PY{o}{=} \PY{n}{init\PYZus{}toy\PYZus{}model}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\PY{n}{loss}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{net}\PY{o}{.}\PY{n}{loss}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{reg}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{)}
\PY{n}{correct\PYZus{}loss} \PY{o}{=} \PY{l+m+mf}{1.182248}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{loss}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Difference between your loss and correct loss:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{abs}\PY{p}{(}\PY{n}{loss} \PY{o}{\PYZhy{}} \PY{n}{correct\PYZus{}loss}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
1.1822479803941373
Difference between your loss and correct loss:
1.9605862711102873e-08
    \end{Verbatim}

    \hypertarget{pts-q2.2-backward-pass-sigmoid}{%
\subsubsection{{[}10pts{]} Q2.2 Backward pass:
Sigmoid}\label{pts-q2.2-backward-pass-sigmoid}}

\begin{itemize}
\tightlist
\item
  For sigmoid activation, complete the computation of \texttt{grads},
  which stores the gradient of the loss with respect to the variables
  \texttt{W1}, \texttt{b1}, \texttt{W2}, and \texttt{b2}.
\end{itemize}

Now debug your backward pass using a numeric gradient check. Again, the
differences should be very small.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Use numeric gradient checking to check your implementation of the backward pass.}
\PY{c+c1}{\PYZsh{} If your implementation is correct, the difference between the numeric and}
\PY{c+c1}{\PYZsh{} analytic gradients should be less than 1e\PYZhy{}8 for each of W1, W2, b1, and b2.}
\PY{k+kn}{from} \PY{n+nn}{utils} \PY{k}{import} \PY{n}{eval\PYZus{}numerical\PYZus{}gradient}

\PY{n}{loss}\PY{p}{,} \PY{n}{grads} \PY{o}{=} \PY{n}{net}\PY{o}{.}\PY{n}{loss}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{reg}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{)}

\PY{c+c1}{\PYZsh{} these should all be very small}
\PY{k}{for} \PY{n}{param\PYZus{}name} \PY{o+ow}{in} \PY{n}{grads}\PY{p}{:}
    \PY{n}{f} \PY{o}{=} \PY{k}{lambda} \PY{n}{W}\PY{p}{:} \PY{n}{net}\PY{o}{.}\PY{n}{loss}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{reg}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
    \PY{n}{param\PYZus{}grad\PYZus{}num} \PY{o}{=} \PY{n}{eval\PYZus{}numerical\PYZus{}gradient}\PY{p}{(}\PY{n}{f}\PY{p}{,} \PY{n}{net}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{n}{param\PYZus{}name}\PY{p}{]}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s1}{ max relative error: }\PY{l+s+si}{\PYZpc{}e}\PY{l+s+s1}{\PYZsq{}}\PY{o}{\PYZpc{}}\PY{p}{(}\PY{n}{param\PYZus{}name}\PY{p}{,} \PY{n}{rel\PYZus{}error}\PY{p}{(}\PY{n}{param\PYZus{}grad\PYZus{}num}\PY{p}{,} \PY{n}{grads}\PY{p}{[}\PY{n}{param\PYZus{}name}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
W2 max relative error: 8.048892e-10
b2 max relative error: 5.553999e-11
W1 max relative error: 1.126755e-08
b1 max relative error: 2.035406e-06
    \end{Verbatim}

    \hypertarget{pts-q2.3-train-the-sigmoid-network}{%
\subsubsection{{[}5pts{]} Q2.3 Train the Sigmoid
network}\label{pts-q2.3-train-the-sigmoid-network}}

To train the network we will use stochastic gradient descent (SGD),
implemented in \texttt{TwoLayerNet.train}. Then we train a two-layer
network on toy data.

\begin{itemize}
\tightlist
\item
  Implement the prediction function \texttt{TwoLayerNet.predict}, which
  is called during training to keep track of training and validation
  accuracy.
\end{itemize}

You should get the final training loss around 0.1, which is good, but
not too great for such a toy problem. One problem is that the gradient
magnitude for W1 (the first layer weights) stays small all the time, and
the neural net doesn't get much ``learning signals''. This has to do
with the saturation problem of the sigmoid activation function.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{net} \PY{o}{=} \PY{n}{init\PYZus{}toy\PYZus{}model}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{std}\PY{o}{=}\PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{)}
\PY{n}{stats} \PY{o}{=} \PY{n}{net}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,}
                  \PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{reg}\PY{o}{=}\PY{l+m+mf}{1e\PYZhy{}5}\PY{p}{,}
                  \PY{n}{num\PYZus{}epochs}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Final training loss: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{stats}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss\PYZus{}history}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} plot the loss history and gradient magnitudes}
\PY{n}{fig}\PY{p}{,} \PY{p}{(}\PY{n}{ax1}\PY{p}{,} \PY{n}{ax2}\PY{p}{)} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{ax1}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{stats}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss\PYZus{}history}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{epoch}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training Loss history}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{ax2}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{stats}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grad\PYZus{}magnitude\PYZus{}history}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{iteration}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZdl{}||}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{nabla\PYZus{}}\PY{l+s+si}{\PYZob{}W1\PYZcb{}}\PY{l+s+s1}{||\PYZdl{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Gradient magnitude history }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+}  \PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{(\PYZdl{}}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{nabla\PYZus{}}\PY{l+s+si}{\PYZob{}W1\PYZcb{}}\PY{l+s+s1}{\PYZdl{})}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{fig}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Final training loss:  0.10926794610680679
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_24_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{pts-q2.4-using-relu-activation}{%
\subsubsection{{[}5pts{]} Q2.4 Using ReLU
activation}\label{pts-q2.4-using-relu-activation}}

The Rectified Linear Unit (ReLU) activation is also widely used:
\(ReLU(x)=max(0,x)\).

\begin{itemize}
\tightlist
\item
  Complete the implementation for the ReLU activation (forward and
  backward) in \texttt{mlp.py}.
\item
  Train the network with ReLU, and report your final training loss.
\end{itemize}

Make sure you first pass the numerical gradient check on toy data.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{net} \PY{o}{=} \PY{n}{init\PYZus{}toy\PYZus{}model}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{std}\PY{o}{=}\PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{)}

\PY{n}{loss}\PY{p}{,} \PY{n}{grads} \PY{o}{=} \PY{n}{net}\PY{o}{.}\PY{n}{loss}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{reg}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss = }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{loss}\PY{p}{)}  \PY{c+c1}{\PYZsh{} correct\PYZus{}loss = 1.320973}

\PY{c+c1}{\PYZsh{} The differences should all be very small}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{checking gradients}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{k}{for} \PY{n}{param\PYZus{}name} \PY{o+ow}{in} \PY{n}{grads}\PY{p}{:}
    \PY{n}{f} \PY{o}{=} \PY{k}{lambda} \PY{n}{W}\PY{p}{:} \PY{n}{net}\PY{o}{.}\PY{n}{loss}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{reg}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
    \PY{n}{param\PYZus{}grad\PYZus{}num} \PY{o}{=} \PY{n}{eval\PYZus{}numerical\PYZus{}gradient}\PY{p}{(}\PY{n}{f}\PY{p}{,} \PY{n}{net}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{n}{param\PYZus{}name}\PY{p}{]}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s1}{ max relative error: }\PY{l+s+si}{\PYZpc{}e}\PY{l+s+s1}{\PYZsq{}}\PY{o}{\PYZpc{}}\PY{p}{(}\PY{n}{param\PYZus{}name}\PY{p}{,} \PY{n}{rel\PYZus{}error}\PY{p}{(}\PY{n}{param\PYZus{}grad\PYZus{}num}\PY{p}{,} \PY{n}{grads}\PY{p}{[}\PY{n}{param\PYZus{}name}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
loss =  1.3037878913298206
checking gradients
W2 max relative error: 3.440708e-09
b2 max relative error: 3.865091e-11
W1 max relative error: 3.561318e-09
b1 max relative error: 8.994864e-10
    \end{Verbatim}

    Now that it's working, let's train the network. Does the net get
stronger learning signals (i.e.~gradients) this time? Report your final
training loss.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{net} \PY{o}{=} \PY{n}{init\PYZus{}toy\PYZus{}model}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{std}\PY{o}{=}\PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{)}
\PY{n}{stats} \PY{o}{=} \PY{n}{net}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,}
                  \PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{n}{reg}\PY{o}{=}\PY{l+m+mf}{1e\PYZhy{}5}\PY{p}{,}
                  \PY{n}{num\PYZus{}epochs}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}

\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Final training loss: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{stats}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss\PYZus{}history}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}

\PY{c+c1}{\PYZsh{} plot the loss history}
\PY{n}{fig}\PY{p}{,} \PY{p}{(}\PY{n}{ax1}\PY{p}{,} \PY{n}{ax2}\PY{p}{)} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{ax1}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{stats}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss\PYZus{}history}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{epoch}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training Loss history}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{ax2}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{stats}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grad\PYZus{}magnitude\PYZus{}history}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{iteration}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZdl{}||}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{nabla\PYZus{}}\PY{l+s+si}{\PYZob{}W1\PYZcb{}}\PY{l+s+s1}{||\PYZdl{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Gradient magnitude history }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+}  \PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{(\PYZdl{}}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{nabla\PYZus{}}\PY{l+s+si}{\PYZob{}W1\PYZcb{}}\PY{l+s+s1}{\PYZdl{})}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{fig}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Final training loss:  0.0178562204869839
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_28_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{application-to-a-real-problem}{%
\subsection{Application to a real
Problem}\label{application-to-a-real-problem}}

\hypertarget{load-mnist-data}{%
\subsubsection{Load MNIST data}\label{load-mnist-data}}

Now that you have implemented a two-layer network that works on toy
data, let's try some real data. The MNIST dataset is a standard machine
learning benchmark. It consists of 70,000 grayscale handwritten digit
images, which we split into 50,000 training, 10,000 validation and
10,000 testing. The images are of size 28x28, which are flattened into
784-d vectors.

\textbf{Note 1}: the function \texttt{get\_MNIST\_data} requires the
\texttt{scikit-learn} package. If you previously did anaconda
installation to set up your Python environment, you should already have
it. Otherwise, you can install it following the instructions here:
http://scikit-learn.org/stable/install.html

\textbf{Note 2}: If you encounter a \texttt{HTTP\ 500} error, that is
likely temporary, just try again.

\textbf{Note 3}: Ensure that the downloaded MNIST file is 55.4MB
(smaller file-sizes could indicate an incomplete download - which is
possible)

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{8}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} load MNIST}
\PY{k+kn}{from} \PY{n+nn}{utils} \PY{k}{import} \PY{n}{get\PYZus{}MNIST\PYZus{}data}
\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{get\PYZus{}MNIST\PYZus{}data}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train data shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train labels shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Validation data shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Validation labels shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Test data shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Test labels shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Train data shape:  (50000, 784)
Train labels shape:  (50000,)
Validation data shape:  (10000, 784)
Validation labels shape:  (10000,)
Test data shape:  (10000, 784)
Test labels shape:  (10000,)
    \end{Verbatim}

    \hypertarget{train-a-network-on-mnist}{%
\subsubsection{Train a network on
MNIST}\label{train-a-network-on-mnist}}

We will now train a network on MNIST with 64 hidden units in the hidden
layer. We train it using SGD, and decrease the learning rate with an
exponential rate over time; this is achieved by multiplying the learning
rate with a constant factor \texttt{learning\_rate\_decay} (which is
less than 1) after each epoch. In effect, we are using a high learning
rate initially, which is good for exploring the solution space, and
using lower learning rates later to encourage convergence to a local
minimum (or
\href{http://www.offconvex.org/2016/03/22/saddlepoints/}{saddle point},
which may happen more often).

\begin{itemize}
\tightlist
\item
  Train your MNIST network with 2 different activation functions:
  sigmoid and ReLU.
\end{itemize}

We first define some variables and utility functions. The
\texttt{plot\_stats} function plots the histories of gradient magnitude,
training loss, and accuracies on the training and validation sets. The
\texttt{show\_net\_weights} function visualizes the weights learned in
the first layer of the network. In most neural networks trained on
visual data, the first layer weights typically show some visible
structure when visualized. Both functions help you to diagnose the
training process.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{9}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{input\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{28} \PY{o}{*} \PY{l+m+mi}{28}
\PY{n}{hidden\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{64}
\PY{n}{num\PYZus{}classes} \PY{o}{=} \PY{l+m+mi}{10}

\PY{c+c1}{\PYZsh{} Plot the loss function and train / validation accuracies}
\PY{k}{def} \PY{n+nf}{plot\PYZus{}stats}\PY{p}{(}\PY{n}{stats}\PY{p}{)}\PY{p}{:}
    \PY{n}{fig}\PY{p}{,} \PY{p}{(}\PY{n}{ax1}\PY{p}{,} \PY{n}{ax2}\PY{p}{,} \PY{n}{ax3}\PY{p}{)} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
    \PY{n}{ax1}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{stats}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grad\PYZus{}magnitude\PYZus{}history}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
    \PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Gradient magnitude history }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZdl{}(}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{nabla\PYZus{}}\PY{l+s+si}{\PYZob{}W1\PYZcb{}}\PY{l+s+s1}{)\PYZdl{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Iteration}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+sa}{r}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZdl{}||}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{nabla\PYZus{}}\PY{l+s+si}{\PYZob{}W1\PYZcb{}}\PY{l+s+s1}{||\PYZdl{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{minimum}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{,}\PY{n}{np}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{n}{stats}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grad\PYZus{}magnitude\PYZus{}history}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{)}
    
    \PY{n}{ax2}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{stats}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss\PYZus{}history}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
    \PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Loss history}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Iteration}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{)}
    
    \PY{n}{ax3}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{stats}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train\PYZus{}acc\PYZus{}history}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} 
    \PY{n}{ax3}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{stats}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}acc\PYZus{}history}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{ax3}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Classification accuracy history}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{ax3}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Epoch}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{ax3}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Clasification accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{fig}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Visualize the weights of the network}
\PY{k+kn}{from} \PY{n+nn}{utils} \PY{k}{import} \PY{n}{visualize\PYZus{}grid}
\PY{k}{def} \PY{n+nf}{show\PYZus{}net\PYZus{}weights}\PY{p}{(}\PY{n}{net}\PY{p}{)}\PY{p}{:}
    \PY{n}{W1} \PY{o}{=} \PY{n}{net}\PY{o}{.}\PY{n}{params}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{W1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
    \PY{n}{W1} \PY{o}{=} \PY{n}{W1}\PY{o}{.}\PY{n}{T}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{28}\PY{p}{,} \PY{l+m+mi}{28}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{visualize\PYZus{}grid}\PY{p}{(}\PY{n}{W1}\PY{p}{,} \PY{n}{padding}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{uint8}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{gca}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{sigmoid-network}{%
\subsubsection{Sigmoid network}\label{sigmoid-network}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{sigmoid\PYZus{}net} \PY{o}{=} \PY{n}{TwoLayerMLP}\PY{p}{(}\PY{n}{input\PYZus{}size}\PY{p}{,} \PY{n}{hidden\PYZus{}size}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{std}\PY{o}{=}\PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Train the network}
\PY{n}{sigmoid\PYZus{}stats} \PY{o}{=} \PY{n}{sigmoid\PYZus{}net}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{,} 
                                  \PY{n}{num\PYZus{}epochs}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} 
                                  \PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{l+m+mf}{1e\PYZhy{}3}\PY{p}{,}  \PY{n}{learning\PYZus{}rate\PYZus{}decay}\PY{o}{=}\PY{l+m+mf}{0.95}\PY{p}{,} 
                                  \PY{n}{reg}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Predict on the training set}
\PY{n}{train\PYZus{}acc} \PY{o}{=} \PY{p}{(}\PY{n}{sigmoid\PYZus{}net}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)} \PY{o}{==} \PY{n}{y\PYZus{}train}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sigmoid final training accuracy: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{train\PYZus{}acc}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Predict on the validation set}
\PY{n}{val\PYZus{}acc} \PY{o}{=} \PY{p}{(}\PY{n}{sigmoid\PYZus{}net}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{)} \PY{o}{==} \PY{n}{y\PYZus{}val}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sigmoid final validation accuracy: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{val\PYZus{}acc}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Predict on the test set}
\PY{n}{test\PYZus{}acc} \PY{o}{=} \PY{p}{(}\PY{n}{sigmoid\PYZus{}net}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)} \PY{o}{==} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sigmoid test accuracy: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{test\PYZus{}acc}\PY{p}{)}

\PY{c+c1}{\PYZsh{} show stats and visualizations}
\PY{n}{plot\PYZus{}stats}\PY{p}{(}\PY{n}{sigmoid\PYZus{}stats}\PY{p}{)}
\PY{n}{show\PYZus{}net\PYZus{}weights}\PY{p}{(}\PY{n}{sigmoid\PYZus{}net}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Epoch 1: loss 79.040004, train\_acc 0.160000, val\_acc 0.266300
Epoch 2: loss 49.814996, train\_acc 0.500000, val\_acc 0.461100
Epoch 3: loss 32.419904, train\_acc 0.640000, val\_acc 0.568300
Epoch 4: loss 21.756599, train\_acc 0.630000, val\_acc 0.639700
Epoch 5: loss 15.148895, train\_acc 0.680000, val\_acc 0.685000
Epoch 6: loss 10.909900, train\_acc 0.680000, val\_acc 0.712600
Epoch 7: loss 8.078106, train\_acc 0.760000, val\_acc 0.737900
Epoch 8: loss 6.166522, train\_acc 0.830000, val\_acc 0.755600
Epoch 9: loss 4.948016, train\_acc 0.780000, val\_acc 0.772900
Epoch 10: loss 4.113118, train\_acc 0.760000, val\_acc 0.785000
Epoch 11: loss 3.455138, train\_acc 0.840000, val\_acc 0.797000
Epoch 12: loss 3.026239, train\_acc 0.840000, val\_acc 0.808100
Epoch 13: loss 2.702231, train\_acc 0.840000, val\_acc 0.819600
Epoch 14: loss 2.438965, train\_acc 0.820000, val\_acc 0.830900
Epoch 15: loss 2.258613, train\_acc 0.900000, val\_acc 0.839900
Epoch 16: loss 2.166625, train\_acc 0.860000, val\_acc 0.846800
Epoch 17: loss 2.098843, train\_acc 0.840000, val\_acc 0.852800
Epoch 18: loss 1.975990, train\_acc 0.910000, val\_acc 0.859300
Epoch 19: loss 1.898398, train\_acc 0.900000, val\_acc 0.862300
Epoch 20: loss 1.876564, train\_acc 0.910000, val\_acc 0.866400
Sigmoid final training accuracy:  0.8721
Sigmoid final validation accuracy:  0.8664
Sigmoid test accuracy:  0.8639
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_34_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_34_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{relu-network}{%
\subsubsection{ReLU network}\label{relu-network}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{relu\PYZus{}net} \PY{o}{=} \PY{n}{TwoLayerMLP}\PY{p}{(}\PY{n}{input\PYZus{}size}\PY{p}{,} \PY{n}{hidden\PYZus{}size}\PY{p}{,} \PY{n}{num\PYZus{}classes}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{std}\PY{o}{=}\PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Train the network}
\PY{n}{relu\PYZus{}stats} \PY{o}{=} \PY{n}{relu\PYZus{}net}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{,} 
                            \PY{n}{num\PYZus{}epochs}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,}
                            \PY{n}{learning\PYZus{}rate}\PY{o}{=}\PY{l+m+mf}{1e\PYZhy{}3}\PY{p}{,} \PY{n}{learning\PYZus{}rate\PYZus{}decay}\PY{o}{=}\PY{l+m+mf}{0.95}\PY{p}{,} 
                            \PY{n}{reg}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\PY{c+c1}{\PYZsh{} Predict on the training set}
\PY{n}{train\PYZus{}acc} \PY{o}{=} \PY{p}{(}\PY{n}{relu\PYZus{}net}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)} \PY{o}{==} \PY{n}{y\PYZus{}train}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ReLU final training accuracy: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{train\PYZus{}acc}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Predict on the validation set}
\PY{n}{val\PYZus{}acc} \PY{o}{=} \PY{p}{(}\PY{n}{relu\PYZus{}net}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{)} \PY{o}{==} \PY{n}{y\PYZus{}val}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ReLU final validation accuracy: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{val\PYZus{}acc}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Predict on the test set}
\PY{n}{test\PYZus{}acc} \PY{o}{=} \PY{p}{(}\PY{n}{relu\PYZus{}net}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)} \PY{o}{==} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ReLU test accuracy: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{test\PYZus{}acc}\PY{p}{)}

\PY{c+c1}{\PYZsh{} show stats and visualizations}
\PY{n}{plot\PYZus{}stats}\PY{p}{(}\PY{n}{relu\PYZus{}stats}\PY{p}{)}
\PY{n}{show\PYZus{}net\PYZus{}weights}\PY{p}{(}\PY{n}{relu\PYZus{}net}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Epoch 1: loss 77.403993, train\_acc 0.890000, val\_acc 0.871800
Epoch 2: loss 47.584593, train\_acc 0.940000, val\_acc 0.888800
Epoch 3: loss 29.867657, train\_acc 0.950000, val\_acc 0.905500
Epoch 4: loss 19.523982, train\_acc 0.940000, val\_acc 0.921400
Epoch 5: loss 13.036818, train\_acc 0.940000, val\_acc 0.926900
Epoch 6: loss 8.991179, train\_acc 0.930000, val\_acc 0.933400
Epoch 7: loss 6.140189, train\_acc 0.970000, val\_acc 0.941900
Epoch 8: loss 4.527342, train\_acc 0.940000, val\_acc 0.945300
Epoch 9: loss 3.236795, train\_acc 0.980000, val\_acc 0.951000
Epoch 10: loss 2.410958, train\_acc 0.970000, val\_acc 0.954300
Epoch 11: loss 1.849616, train\_acc 0.980000, val\_acc 0.957000
Epoch 12: loss 1.393771, train\_acc 0.990000, val\_acc 0.959100
Epoch 13: loss 1.163523, train\_acc 0.980000, val\_acc 0.958900
Epoch 14: loss 0.993990, train\_acc 0.940000, val\_acc 0.961200
Epoch 15: loss 0.815937, train\_acc 0.970000, val\_acc 0.961500
Epoch 16: loss 0.683699, train\_acc 0.960000, val\_acc 0.962200
Epoch 17: loss 0.625457, train\_acc 0.980000, val\_acc 0.962500
Epoch 18: loss 0.487950, train\_acc 0.990000, val\_acc 0.965200
Epoch 19: loss 0.452108, train\_acc 0.990000, val\_acc 0.965700
Epoch 20: loss 0.404945, train\_acc 0.980000, val\_acc 0.965900
ReLU final training accuracy:  0.97276
ReLU final validation accuracy:  0.9659
ReLU test accuracy:  0.9653
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_36_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_36_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{pts-q2.5}{%
\subsubsection{{[}5pts{]} Q2.5}\label{pts-q2.5}}

Which activation function would you choose in practice? Why?

    In this problem, I choose ReLu, because it has a better performance.
ReLu does not suffer from gradient vanishment, but Sigmoid and tanh do.

In practice, we play with different activation functions and compare
their performances to determine which to choose.

In fact, different activation functions have different pros and cons,
which is a hot topic in academia.

    \hypertarget{pts-problem-3-simple-regularization-methods}{%
\subsection{{[}20pts{]} Problem 3: Simple Regularization
Methods}\label{pts-problem-3-simple-regularization-methods}}

You may have noticed the \texttt{reg} parameter in
\texttt{TwoLayerMLP.loss}, controlling ``regularization strength''. In
learning neural networks, aside from minimizing a loss function
\(\mathcal{L}(\theta)\) with respect to the network parameters
\(\theta\), we usually explicitly or implicitly add some regularization
term to reduce overfitting. A simple and popular regularization strategy
is to penalize some \emph{norm} of \(\theta\).

    \hypertarget{pts-q3.1-l2-regularization}{%
\subsubsection{{[}10pts{]} Q3.1: L2
regularization}\label{pts-q3.1-l2-regularization}}

We can penalize the L2 norm of \(\theta\): we modify our objective
function to be \(\mathcal{L}(\theta) + \lambda \|\theta\|^2\) where
\(\lambda\) is the weight of regularization. We will minimize this
objective using gradient descent with step size \(\eta\). Derive the
update rule: at time \(t+1\), express the new parameters
\(\theta_{t+1}\) in terms of the old parameters \(\theta_t\), the
gradient \(g_t=\frac{\partial \mathcal{L}}{\partial \theta_t}\),
\(\eta\), and \(\lambda\).

    \textbf{Gradient descent with L2 Regularization:}

\[ \theta_{t+1} = \theta_{t} - \eta (\frac{\partial L}{\partial \theta_t } + \lambda \theta_t)\]

    \hypertarget{pts-q3.2-l1-regularization}{%
\subsubsection{{[}10pts{]} Q3.2: L1
regularization}\label{pts-q3.2-l1-regularization}}

Now let's consider L1 regularization: our objective in this case is
\(\mathcal{L}(\theta) + \lambda \|\theta\|_1\). Derive the update rule.

(Technically this becomes \emph{Sub-Gradient} Descent since the L1 norm
is not differentiable at 0. But practically it is usually not an issue.)

    \textbf{Gradient descent with L2 Regularization:}

\[ \theta_{t+1}^{(i)}=\left\{
\begin{array}{rcl}
\theta_t^{(i)}-\eta (g_t+\lambda)     &      & {\theta_t^{(i)} > 0}\\
\theta_t^{(i)}-\eta (g_t-\lambda)       &      & {\theta_t^{(i)} \leq 0}
\end{array} \right. \quad\quad\forall 1\leq i\leq d\]

where \(d\) is the dimension of \(\theta\).


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
