\BOOKMARK [1][-]{section.1}{Problem Set 3: Neural Networks}{}% 1
\BOOKMARK [2][-]{subsubsection.1.0.1}{In part 2 \(programming\) of this assignment, you DO NOT need to make any modification code in this IPython Notebook. Instead you will implement your own simple neural network in the mlp.py file. Please attach your written solutions for part 1 and part 3 in this IPython Notebook.}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.1}{[30pts] Problem 1: Backprop in a simple MLP}{section.1}% 3
\BOOKMARK [2][-]{subsection.1.2}{[30pts] Problem 2 \(Programming\): Implementing a simple MLP}{section.1}% 4
\BOOKMARK [3][-]{subsubsection.1.2.1}{[5pts] Q2.1 Forward pass: Sigmoid}{subsection.1.2}% 5
\BOOKMARK [3][-]{subsubsection.1.2.2}{[10pts] Q2.2 Backward pass: Sigmoid}{subsection.1.2}% 6
\BOOKMARK [3][-]{subsubsection.1.2.3}{[5pts] Q2.3 Train the Sigmoid network}{subsection.1.2}% 7
\BOOKMARK [3][-]{subsubsection.1.2.4}{[5pts] Q2.4 Using ReLU activation}{subsection.1.2}% 8
\BOOKMARK [2][-]{subsection.1.3}{Application to a real Problem}{section.1}% 9
\BOOKMARK [3][-]{subsubsection.1.3.1}{Load MNIST data}{subsection.1.3}% 10
\BOOKMARK [3][-]{subsubsection.1.3.2}{Train a network on MNIST}{subsection.1.3}% 11
\BOOKMARK [3][-]{subsubsection.1.3.3}{Sigmoid network}{subsection.1.3}% 12
\BOOKMARK [3][-]{subsubsection.1.3.4}{ReLU network}{subsection.1.3}% 13
\BOOKMARK [3][-]{subsubsection.1.3.5}{[5pts] Q2.5}{subsection.1.3}% 14
\BOOKMARK [2][-]{subsection.1.4}{[20pts] Problem 3: Simple Regularization Methods}{section.1}% 15
\BOOKMARK [3][-]{subsubsection.1.4.1}{[10pts] Q3.1: L2 regularization}{subsection.1.4}% 16
\BOOKMARK [3][-]{subsubsection.1.4.2}{[10pts] Q3.2: L1 regularization}{subsection.1.4}% 17
